{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Cosine Pose Similarity Metric (aCPSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import cv\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pose coordinates of the focal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_cords gives the coordinates of the focal points, in this example for detecting posture\n",
    "# we need the left/right shoulder coords and the left/right hip (these are the focal points)\n",
    "def extract_coords(rgb_image, detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    \n",
    "    pose_coords = []\n",
    "\n",
    "    # Loop through the detected poses to visualize.\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        # Draw the pose landmarks.\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        \n",
    "        pose_coords.append([pose_landmarks_proto.landmark[11].x, pose_landmarks_proto.landmark[11].y])\n",
    "        pose_coords.append([pose_landmarks_proto.landmark[12].x, pose_landmarks_proto.landmark[12].y])\n",
    "        pose_coords.append([pose_landmarks_proto.landmark[23].x, pose_landmarks_proto.landmark[23].y])\n",
    "        pose_coords.append([pose_landmarks_proto.landmark[24].x, pose_landmarks_proto.landmark[24].y])\n",
    "\n",
    "    return pose_coords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Benchmark Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the bench mark poses can be explaine best with how they work.\n",
    "# from the whole dataset, if you take 100 of the left-tilt posture of people and make an average of their\n",
    "# shoulder and hip coordinates then that is the average left-tilt coordinates of the posture, aka left-tilt benchmark pose\n",
    "\n",
    "            \n",
    "\n",
    "model_path = 'pose_landmarker_lite.task'\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_segmentation_masks=True)\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "##################\n",
    "f = 'path/to/folder/for/benchmark/poses'  ## folder path\n",
    "\n",
    "## BM = benchmark\n",
    "## a process for this model\n",
    "bm_poses = []\n",
    "bm_left = []\n",
    "bm_right = []\n",
    "bm_straight = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "als = [0, 0]\n",
    "ars = [0, 0]\n",
    "alh = [0, 0]\n",
    "arh = [0, 0]\n",
    "\n",
    "for images in os.listdir(f + '/left'):\n",
    "    path = f + '/left'\n",
    "    image = mp.Image.create_from_file(path +'/'+images)\n",
    "    detection_result = detector.detect(image)\n",
    "    p = extract_coords(image.numpy_view(), detection_result)    \n",
    "    \n",
    "    als = [als[0] + p[0][0], als[1] + p[0][1]]\n",
    "    ars = [ars[0] + p[1][0], ars[1] + p[1][1]]\n",
    "    alh = [alh[0] + p[2][0], alh[1] + p[2][1]]\n",
    "    arh = [arh[0] + p[3][0], arh[1] + p[3][1]]\n",
    "\n",
    "    i += 1\n",
    "    if i == 100:\n",
    "        als = [als[0]/i, als[1]/i]\n",
    "        ars = [ars[0]/i, ars[1]/i]\n",
    "        alh = [alh[0]/i, alh[1]/i]\n",
    "        arh = [arh[0]/i, arh[1]/i]\n",
    "        bm_left = [als, ars, alh, arh]\n",
    "        print(f'left: {bm_left}')\n",
    "        i = 0\n",
    "        break\n",
    "\n",
    "for images in os.listdir(f + '/right'):\n",
    "    path = f + '/right'\n",
    "    image = mp.Image.create_from_file(path +'/'+images)\n",
    "    detection_result = detector.detect(image)\n",
    "    p = extract_coords(image.numpy_view(), detection_result)    \n",
    "    \n",
    "    als = [als[0] + p[0][0], als[1] + p[0][1]]\n",
    "    ars = [ars[0] + p[1][0], ars[1] + p[1][1]]\n",
    "    alh = [alh[0] + p[2][0], alh[1] + p[2][1]]\n",
    "    arh = [arh[0] + p[3][0], arh[1] + p[3][1]]\n",
    "\n",
    "    i += 1\n",
    "    if i == 100:\n",
    "        als = [als[0]/i, als[1]/i]\n",
    "        ars = [ars[0]/i, ars[1]/i]\n",
    "        alh = [alh[0]/i, alh[1]/i]\n",
    "        arh = [arh[0]/i, arh[1]/i]\n",
    "        bm_right = [als, ars, alh, arh]\n",
    "        print(f'right: {bm_right}')\n",
    "        i = 0\n",
    "        break\n",
    "\n",
    "for images in os.listdir(f + '/straight'):\n",
    "    path = f + '/straight'\n",
    "    image = mp.Image.create_from_file(path +'/'+images)\n",
    "    detection_result = detector.detect(image)\n",
    "    p = extract_coords(image.numpy_view(), detection_result)    \n",
    "    \n",
    "    als = [als[0] + p[0][0], als[1] + p[0][1]]\n",
    "    ars = [ars[0] + p[1][0], ars[1] + p[1][1]]\n",
    "    alh = [alh[0] + p[2][0], alh[1] + p[2][1]]\n",
    "    arh = [arh[0] + p[3][0], arh[1] + p[3][1]]\n",
    "\n",
    "    i += 1\n",
    "    if i == 100:\n",
    "        als = [als[0]/i, als[1]/i]\n",
    "        ars = [ars[0]/i, ars[1]/i]\n",
    "        alh = [alh[0]/i, alh[1]/i]\n",
    "        arh = [arh[0]/i, arh[1]/i]\n",
    "        bm_straight = [als, ars, alh, arh]\n",
    "        print(f'straight: {bm_straight}')\n",
    "        i = 0\n",
    "        break\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used for calculating the pose similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculates the similiarity between two vectors using the cosine of their angles\n",
    "def cos_similarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))    \n",
    "\n",
    "# bmp = benchmark pose\n",
    "# calculates the difference in x-coordinates of the benchmark pose and the \n",
    "# given pose which we do not know yet its classification\n",
    "def x_diff(bmp, t_p):\n",
    "    sump = 0 \n",
    "    x = 0\n",
    "    while (x < 2):\n",
    "        sump += bmp[x][0] - t_p[x][0]\n",
    "        x+=1\n",
    "    return sump / 2\n",
    "\n",
    "\n",
    "def cosine_diff_conf(yhat, t_p):\n",
    "    p_conf = []\n",
    "\n",
    "    exp_bias = 0.5\n",
    "\n",
    "    p_conf.append((np.power(1 - np.abs(x_diff(bm_left, t_p)), yhat[0] + exp_bias)))\n",
    "    p_conf.append((np.power(1 - np.abs(x_diff(bm_right, t_p)), yhat[1] + exp_bias)))\n",
    "    p_conf.append((np.power(1 - np.abs(x_diff(bm_straight, t_p)), yhat[2] + exp_bias)))\n",
    "    \n",
    "    return p_conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the aCSPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block runs the aCSPM. This involves taking the testing images and using the stand-alone model to predict them \\\n",
    "for each of the three classifications. This notated as yhat. Then the benchmark poses and averages are calculated with the \\\n",
    "helper functions. Results are stored in left, right and straight lists. For an average these results need to be divided by the  \n",
    "number of images of the respective test class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'path/for/testing'\n",
    "\n",
    "left = []\n",
    "right = []\n",
    "straight = []\n",
    "\n",
    "gamma_left = []\n",
    "gamma_right = []\n",
    "gamma_straight = []\n",
    "\n",
    "for img_file in os.listdir(dir_name + '/left'):\n",
    "    imgt = cv2.imread(dir_name + '/left/'+img_file)\n",
    "    resize = tf.image.resize(imgt, (256,256))\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "    \n",
    "    if yhat[0][0] == max(yhat[0]):\n",
    "        left.append(yhat[0][0])\n",
    "\n",
    "    image = mp.Image.create_from_file(dir_name+'/left/'+img_file)\n",
    "    detection_result = detector.detect(image)\n",
    "\n",
    "    t_p = extract_coords(image.numpy_view(), detection_result)\n",
    "    \n",
    "    y = cosine_diff_conf([yhat[0][0], yhat[0][1], yhat[0][2]], t_p)\n",
    "\n",
    "    if y[0] == max(y):\n",
    "        gamma_left.append(y[0])\n",
    "        \n",
    "for img_file in os.listdir(dir_name + '/right'):\n",
    "    imgt = cv2.imread(dir_name + '/right/'+img_file)\n",
    "    resize = tf.image.resize(imgt, (256,256))\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "    \n",
    "    if yhat[0][1] == max(yhat[0]):\n",
    "        right.append(yhat[0][1])\n",
    "\n",
    "    image = mp.Image.create_from_file(dir_name+'/right/'+img_file)\n",
    "    detection_result = detector.detect(image)\n",
    "\n",
    "    t_p = extract_coords(image.numpy_view(), detection_result)\n",
    "    \n",
    "    y = cosine_diff_conf([yhat[0][0], yhat[0][1], yhat[0][2]], t_p)\n",
    "\n",
    "    if y[1] == max(y):\n",
    "        gamma_right.append(y[1])\n",
    "        \n",
    "        \n",
    "for img_file in os.listdir(dir_name + '/straight'):\n",
    "    imgt = cv2.imread(dir_name + '/straight/'+img_file)\n",
    "    resize = tf.image.resize(imgt, (256,256))\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "    print(f'normal: {yhat[0]}')\n",
    "\n",
    "    if yhat[0][2] == max(yhat[0]):\n",
    "        straight.append(yhat[0][2])\n",
    "\n",
    "    image = mp.Image.create_from_file(dir_name+'/straight/'+img_file)\n",
    "    detection_result = detector.detect(image)\n",
    "    \n",
    "    t_p = extract_coords(image.numpy_view(), detection_result)\n",
    "    \n",
    "    y = cosine_diff_conf([yhat[0][0], yhat[0][1], yhat[0][2]], t_p)\n",
    "    \n",
    "    print(f'gamma: {y}')\n",
    "    if y[2] == max(y):\n",
    "        gamma_straight.append(y[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the results are shown below.\n",
    "\n",
    "First three classifications are from the stand-alone model such as the one from cnn-lstm.ipynb.\\\n",
    "The other three (PSM) classifications are from pose similarity metric which fuses the landmarks and the stand-alone model.\\\n",
    "The images used for these tests are sub-par, low-quality, and bad lighting hence the low accuracies. The PSM seems to be \\\n",
    "fixing them very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n stands for the number of images, normally they do not need to be the same number\n",
    "n = 100\n",
    "print(f'class acc (left): {len(left) / n}')        \n",
    "print(f'class acc (right): {len(right) / n}')\n",
    "print(f'class acc (straight): {len(straight) / n}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class acc (left): 0.5714285714285714\n",
    "# class acc (right): 0.9411764705882353\n",
    "# class acc (straight): 0.0\n",
    "# class PSM acc (left): 0.9523809523809523\n",
    "# class PSM acc (right): 0.9411764705882353\n",
    "# class PSM acc (straight): 0.8461538461538461\n",
    "\n",
    "# class acc (left): 0.8095238095238095\n",
    "# class acc (right): 0.8823529411764706\n",
    "# class acc (straight): 0.23076923076923078\n",
    "# class PSM acc (left): 0.8095238095238095\n",
    "# class PSM acc (right): 0.7058823529411765\n",
    "# class PSM acc (straight): 0.9230769230769231\n",
    "\n",
    "# class acc (left): 0.6666666666666666\n",
    "# class acc (right): 0.8823529411764706\n",
    "# class acc (straight): 0.23076923076923078\n",
    "# class PSM acc (left): 0.8095238095238095\n",
    "# class PSM acc (right): 0.9411764705882353\n",
    "# class PSM acc (straight): 0.8461538461538461\n",
    "\n",
    "# class acc (left): 0.9523809523809523\n",
    "# class acc (right): 0.9411764705882353\n",
    "# class acc (straight): 0.15384615384615385\n",
    "# class PSM acc (left): 0.9523809523809523\n",
    "# class PSM acc (right): 0.9411764705882353\n",
    "# class PSM acc (straight): 0.8461538461538461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
